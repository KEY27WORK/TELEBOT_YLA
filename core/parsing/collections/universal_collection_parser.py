""" ğŸ§¾ universal_collection_parser.py â€” Ğ£Ğ½Ñ–Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ¿Ğ°Ñ€ÑĞµÑ€ ĞºĞ¾Ğ»ĞµĞºÑ†Ñ–Ğ¹ YoungLA (US, EU, UK)

ğŸ”¹ ĞšĞ»Ğ°Ñ `UniversalCollectionParser`:
- Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ°Ñ” Ñ€ĞµĞ³Ñ–Ğ¾Ğ½ ÑĞ°Ğ¹Ñ‚Ñƒ (Ğ²Ğ°Ğ»ÑÑ‚Ñƒ) Ğ·Ğ° URL
- Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ÑƒÑ” HTML-ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºÑƒ Ñ‡ĞµÑ€ĞµĞ· WebDriverService
- ĞŸĞ°Ñ€ÑĞ¸Ñ‚ÑŒ JSON-LD (Ğ¿Ñ€Ñ–Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ½Ğ¾) Ğ°Ğ±Ğ¾ DOM (fallback)
- Ğ’Ğ¸Ğ´Ğ°Ñ” ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½ÑŒ Ğ½Ğ° Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¸

âœ… SOLID:
- SRP: Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ°Ñ” Ğ»Ğ¸ÑˆĞµ Ğ·Ğ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ ĞºĞ¾Ğ»ĞµĞºÑ†Ñ–Ğ¹
- OCP: Ğ»ĞµĞ³ĞºĞ¾ Ñ€Ğ¾Ğ·ÑˆĞ¸Ñ€ÑÑ”Ñ‚ÑŒÑÑ (Ğ½Ğ°Ğ¿Ñ€Ğ¸ĞºĞ»Ğ°Ğ´, Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¸Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ–Ğ²)
"""

# ğŸ“¦ Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ–
import json
import logging
import asyncio

# ğŸŒ ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ HTML
from bs4 import BeautifulSoup

# ğŸ§± Ğ¡ĞµÑ€Ğ²Ñ–ÑĞ¸
from core.webdriver.webdriver_service import WebDriverService


class UniversalCollectionParser:
    """ğŸ§¾ ĞŸĞ°Ñ€ÑĞµÑ€ ĞºĞ¾Ğ»ĞµĞºÑ†Ñ–Ğ¹ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ–Ğ² Ğ· ÑĞ°Ğ¹Ñ‚Ñ–Ğ² YoungLA (US ğŸ‡ºğŸ‡¸, EU ğŸ‡ªğŸ‡º, UK ğŸ‡¬ğŸ‡§).

    Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ”Ñ‚ÑŒÑÑ Ğ´Ğ»Ñ Ğ²Ğ¸Ñ‚ÑĞ³ÑƒĞ²Ğ°Ğ½Ğ½Ñ ÑƒÑÑ–Ñ… Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½ÑŒ Ğ½Ğ° Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¸ Ğ² ĞºĞ¾Ğ»ĞµĞºÑ†Ñ–Ñ—.
    """

    def __init__(self, url: str):
        """
        :param url: ĞŸĞ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ Ğ½Ğ° ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºÑƒ ĞºĞ¾Ğ»ĞµĞºÑ†Ñ–Ñ—
        """
        self.url = url
        self.soup = None
        self.page_source = None
        self.currency = self._detect_currency()

    def _detect_currency(self) -> str:
        """ğŸŒ Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ°Ñ” Ğ²Ğ°Ğ»ÑÑ‚Ñƒ (Ñ€ĞµĞ³Ñ–Ğ¾Ğ½) Ğ·Ğ° URL."""
        if "eu." in self.url:
            return "EUR"
        elif "uk." in self.url:
            return "GBP"
        return "USD"

    async def fetch_page(self) -> bool:
        """ğŸŒ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ÑƒÑ” HTML-ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºÑƒ ĞºĞ¾Ğ»ĞµĞºÑ†Ñ–Ñ— Ñ‡ĞµÑ€ĞµĞ· WebDriver."""
        self.page_source = await asyncio.to_thread(
            WebDriverService().fetch_page_source, self.url
        )

        if self.page_source and len(self.page_source) > 1000:
            self.soup = BeautifulSoup(self.page_source, "html.parser")
            logging.info(f"âœ… Ğ¡Ñ‚Ğ¾Ñ€Ñ–Ğ½ĞºĞ° ĞºĞ¾Ğ»ĞµĞºÑ†Ñ–Ñ— Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ°: {self.url}")
            return True

        logging.error(f"âŒ ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºÑƒ: {self.url}")
        return False

    async def extract_product_links(self) -> list[str]:
        """ğŸ”— Ğ’Ğ¸Ñ‚ÑĞ³ÑƒÑ” Ğ²ÑÑ– Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ Ğ½Ğ° Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¸ Ğ· ĞºĞ¾Ğ»ĞµĞºÑ†Ñ–Ñ—.

        ĞŸÑ€Ğ¾Ğ±ÑƒÑ”:
        - ğŸ“„ JSON-LD (Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğµ Ğ´Ğ¶ĞµÑ€ĞµĞ»Ğ¾)
        - ğŸŒ DOM-Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ (Ñ€ĞµĞ·ĞµÑ€Ğ²Ğ½Ğµ Ğ´Ğ¶ĞµÑ€ĞµĞ»Ğ¾)

        :return: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿Ğ¾Ğ²Ğ½Ğ¸Ñ… URL-Ğ°Ğ´Ñ€ĞµÑ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ–Ğ²
        """
        if not await self.fetch_page():
            logging.warning("âŒ Ğ¡Ñ‚Ğ¾Ñ€Ñ–Ğ½ĞºĞ° Ğ½Ğµ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ° â€” Ğ¿Ğ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ”Ğ¼Ğ¾ Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ñ–Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº.")
            return []

        product_links = []

        # --- ğŸ“„ JSON-LD Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ ---
        for script in self.soup.find_all("script", type="application/ld+json"):
            try:
                data = json.loads(script.string.strip())
                if data.get("@type") == "CollectionPage" and "mainEntity" in data:
                    for item in data["mainEntity"].get("itemListElement", []):
                        url = item.get("item", {}).get("url")
                        if url:
                            product_links.append(url)

                if product_links:
                    logging.info(f"âœ… Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(product_links)} Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ–Ğ² Ñ‡ĞµÑ€ĞµĞ· JSON-LD")
                    return product_links

            except Exception as e:
                logging.warning(f"âš ï¸ ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ñƒ JSON-LD: {e}")

        # --- ğŸŒ DOM fallback ---
        logging.info("ğŸ” JSON-LD Ğ½Ğµ ÑĞ¿Ñ€Ğ°Ñ†ÑĞ²Ğ°Ğ². ĞŸÑ€Ğ¾Ğ±ÑƒÑ”Ğ¼Ğ¾ Ğ¿Ğ°Ñ€ÑĞ¸Ñ‚Ğ¸ DOM...")

        try:
            product_elements = self.soup.select("a[href*='/products/']")
            for a in product_elements:
                href = a.get("href")
                if href and "/products/" in href:
                    full_url = self._build_full_url(href)
                    if full_url not in product_links:
                        product_links.append(full_url)

            if product_links:
                logging.info(f"ğŸ“¦ Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(product_links)} Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ–Ğ² Ñ‡ĞµÑ€ĞµĞ· DOM.")
            else:
                logging.warning("âš ï¸ DOM-Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ½Ğµ Ğ´Ğ°Ğ² Ğ¶Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñƒ.")

        except Exception as e:
            logging.error(f"âŒ ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ñƒ DOM: {e}")

        return product_links

    def _build_full_url(self, href: str) -> str:
        """ğŸ—ï¸ Ğ¤Ğ¾Ñ€Ğ¼ÑƒÑ” Ğ¿Ğ¾Ğ²Ğ½Ğ¸Ğ¹ URL Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñƒ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ñ– Ğ²Ñ–Ğ´Ğ½Ğ¾ÑĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ."""
        base = (
            "https://eu.youngla.com" if "eu." in self.url else
            "https://uk.youngla.com" if "uk." in self.url else
            "https://www.youngla.com"
        )
        return href if href.startswith("http") else f"{base}{href}"

    def _get_domain(self) -> str:
        """ğŸŒ ĞŸĞ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ” Ğ´Ğ¾Ğ¼ĞµĞ½ Ğ¿Ğ¾Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ ÑĞ°Ğ¹Ñ‚Ñƒ."""
        if "eu." in self.url:
            return "eu.youngla.com"
        elif "uk." in self.url:
            return "uk.youngla.com"
        return "www.youngla.com"

    def get_currency(self) -> str:
        """ğŸ’± ĞŸĞ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ” Ğ²Ğ°Ğ»ÑÑ‚Ñƒ ÑĞ°Ğ¹Ñ‚Ñƒ."""
        return self.currency
