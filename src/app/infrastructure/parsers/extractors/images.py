# üñºÔ∏è src/app/infrastructure/parsers/extractors/images.py
"""
üñºÔ∏è ImagesMixin ‚Äî –Ω–∞–±—ñ—Ä —É—Ç–∏–ª—ñ—Ç –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –≥–æ–ª–æ–≤–Ω–æ–≥–æ –π –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å —Ç–æ–≤–∞—Ä—É.

üîπ –ù–æ—Ä–º–∞–ª—ñ–∑—É—î URL (Shopify —Å—É—Ñ—ñ–∫—Å–∏, query-–ø–∞—Ä–∞–º–µ—Ç—Ä–∏) —Ç–∞ –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤—É—î –∑–∞–π–≤—ñ –∫–∞—Ä—Ç–∏–Ω–∫–∏.
üîπ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –¥–∞–Ω—ñ –∑ JSON-LD, HTML-–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ñ–≤ —Ç–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π–Ω–∏—Ö —Ñ—ñ–ª—å—Ç—Ä—ñ–≤.
üîπ –ü—ñ–¥—Ç—Ä–∏–º—É—î –æ–±–º–µ–∂–µ–Ω–Ω—è —Å–ø–∏—Å–∫—É, –≤—ñ–¥—Å—ñ—é–≤–∞–Ω–Ω—è ¬´–º–∞–ª–∏—Ö¬ª –∑–æ–±—Ä–∞–∂–µ–Ω—å —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø–æ—Ä—è–¥–∫—É.
"""

from __future__ import annotations

# üåê –ó–æ–≤–Ω—ñ—à–Ω—ñ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏
import re									# üß™ –†–µ–≥—É–ª—è—Ä–Ω—ñ –≤–∏—Ä–∞–∑–∏ –¥–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä—ñ–≤
from bs4.element import Tag				# üß± –ù–æ–¥–∏ BeautifulSoup

# üî† –°–∏—Å—Ç–µ–º–Ω—ñ —ñ–º–ø–æ—Ä—Ç–∏
from typing import (						# üß∞ –¢–∏–ø—ñ–∑–∞—Ü—ñ—ó –¥–ª—è –ø—Ä–æ—Ç–æ–∫–æ–ª—ñ–≤ —ñ –∫–æ–ª–µ–∫—Ü—ñ–π
    TYPE_CHECKING,
    Any,
    Dict,
    Iterable,
    List,
    Optional,
    Protocol,
    Tuple,
    cast,
)

# üß© –í–Ω—É—Ç—Ä—ñ—à–Ω—ñ –º–æ–¥—É–ª—ñ –ø—Ä–æ—î–∫—Ç—É
from app.infrastructure.parsers.extractors.base import (			# üîó –°–ø—ñ–ª—å–Ω—ñ —É—Ç–∏–ª—ñ—Ç–∏ –¥–ª—è –µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ñ–≤
    Selectors,
    _ConfigSnapshot,
    _normalize_image_url,
    _strip_query,
    logger,
    uniq_keep_order,
)

if TYPE_CHECKING:													# üß† –ü—ñ–¥–∫–∞–∑–∫–∏ –ª–∏—à–µ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
    from bs4 import BeautifulSoup									# noqa: F401


# ================================
# üß± –î–û–ü–û–ú–Ü–ñ–ù–Ü –¢–ò–ü–ò
# ================================
class _ImagesHost(Protocol):
    """
    üß± –ü—Ä–æ—Ç–æ–∫–æ–ª —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞, —è–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î `ImagesMixin`.
    """

    soup: "BeautifulSoup"											# ü•£ DOM-–¥–µ—Ä–µ–≤–æ –ø—Ä–æ–¥—É–∫—Ç—É

    def _main_image_from_json_ld(self) -> Optional[str]:			# üîç –ì–æ–ª–æ–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ JSON-LD
        ...

    def _images_from_json_ld(self) -> Iterable[str]:				# üñºÔ∏è –£—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ JSON-LD
        ...


# ================================
# üñºÔ∏è –ú–Ü–ö–°–ò–ù –ó–û–ë–†–ê–ñ–ï–ù–¨
# ================================
class ImagesMixin:
    """
    üñºÔ∏è –ù–∞–¥–∞—î –º–µ—Ç–æ–¥–∏ –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –≥–æ–ª–æ–≤–Ω–æ–≥–æ —Ç–∞ –≤—Å—ñ—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å —Ç–æ–≤–∞—Ä—É.
    """

    _S: Selectors													# üß∑ –ù–∞–±—ñ—Ä CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä—ñ–≤ —ñ–∑ –±–∞–∑–æ–≤–æ–≥–æ –µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞

    # ================================
    # üîß –î–û–ü–û–ú–Ü–ñ–ù–Ü –ù–û–†–ú–ê–õ–Ü–ó–ê–¢–û–†–ò
    # ================================
    def _canonicalize_shopify(self, url: str) -> str:
        """
        üîß –ü—Ä–∏–±–∏—Ä–∞—î Shopify-—Å—É—Ñ—ñ–∫—Å–∏ –Ω–∞ –∫—à—Ç–∞–ª—Ç `_200x200` –∑—ñ —à–ª—è—Ö—É.
        """
        cleaned = re.sub(
            r"_(\d+x\d+|\d+x)(?=\.(?:jpe?g|png|webp|avif)(?:$|\?))",
            "",
            url,
            flags=re.IGNORECASE,
        )
        if cleaned != url:
            logger.debug("üßº Shopify canonicalized: '%s' ‚Üí '%s'.", url, cleaned)
        return cleaned

    def _normalize_img(self, url: str) -> str:
        """
        üßº –ü–æ–≤–Ω–∏–π —Ü–∏–∫–ª –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó: –∫–∞–Ω–æ–Ω—ñ–∑–∞—Ü—ñ—è + –æ–±—Ä—ñ–∑–∫–∞ query-–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤.
        """
        normalized = _normalize_image_url(url)
        canonical = self._canonicalize_shopify(normalized)
        stripped = _strip_query(canonical)
        logger.debug("üßº normalize_img: '%s' ‚Üí '%s'.", url, stripped)
        return stripped

    # ================================
    # üñºÔ∏è –ì–û–õ–û–í–ù–ï –ó–û–ë–†–ê–ñ–ï–ù–ù–Ø
    # ================================
    def extract_main_image(self) -> str:
        """
        üñºÔ∏è –ü–æ–≤–µ—Ä—Ç–∞—î –≥–æ–ª–æ–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (—Å–ø–æ—á–∞—Ç–∫—É JSON-LD, –¥–∞–ª—ñ ‚Äî HTML-—Ñ–æ–ª–±–µ–∫).
        """
        host = cast(_ImagesHost, self)									# üß≠ –ù–∞–¥–∞—î–º–æ –¥–æ—Å—Ç—É–ø –¥–æ soup/json-ld

        logger.debug("üñºÔ∏è –ü–æ—á–∏–Ω–∞—î–º–æ –ø–æ—à—É–∫ –≥–æ–ª–æ–≤–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.")
        img_url = host._main_image_from_json_ld()						# üîç 1) –ü—Ä—è–º–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑ JSON-LD
        if img_url:
            logger.debug("üñºÔ∏è –ì–æ–ª–æ–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ JSON-LD: %s", img_url)
            return img_url												# ‚úÖ –Ø–∫—â–æ —Ç–∞–º —î URL ‚Äî —Ü–µ –Ω–∞–π–±–µ–∑–ø–µ—á–Ω—ñ—à–µ –¥–∂–µ—Ä–µ–ª–æ

        for selector in self._S.MAIN_IMAGE_LIST:						# üîé 2) –ü—Ä–æ—Ö–æ–¥–∏–º–æ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º DOM
            tag_or_none = host.soup.select_one(selector)				# üåø –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π –∑–±—ñ–≥
            if tag_or_none is None:
                continue

            if isinstance(tag_or_none, Tag) and tag_or_none.name == "meta":
                url_candidate = str(tag_or_none.get("content") or "")	# üè∑Ô∏è <meta property="og:image">, etc.
                normalized = _normalize_image_url(url_candidate)		# üßº –ü—ñ–¥—á–∏—â–∞—î–º–æ URL
                if normalized:
                    logger.debug("üñºÔ∏è DOM meta-—Å–µ–ª–µ–∫—Ç–æ—Ä '%s' –¥–∞–≤ –≥–æ–ª–æ–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.", selector)
                    return normalized									# ‚úÖ –ó–Ω–∞–π—à–ª–∏ –∫–∞–Ω–æ–Ω—ñ—á–Ω—É –∫–∞—Ä—Ç–∏–Ω–∫—É
                continue

            try:
                tag = cast(Tag, tag_or_none)							# üß± –û—á—ñ–∫—É—î–º–æ –∑–≤–∏—á–∞–π–Ω–∏–π <img>/<picture>
                candidates = [											# üìã –ü–æ—Ä—è–¥–æ–∫ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç—ñ–≤ –∞—Ç—Ä–∏–±—É—Ç—ñ–≤
                    tag.get("src"),									#   ‚Ä¢ –∫–ª–∞—Å–∏—á–Ω–∏–π src
                    tag.get("data-src"),								#   ‚Ä¢ –ª—ñ–Ω–∏–≤–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
                    tag.get("data-original"),							#   ‚Ä¢ custom –∞—Ç—Ä–∏–±—É—Ç
                    self._attr_first(token=tag.get("data-srcset")),	#   ‚Ä¢ –±–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π srcset
                ]
                raw_url = next((str(value) for value in candidates if value), "")	# üéØ –ü–µ—Ä—à–∏–π –Ω–µ–Ω—É–ª—å–æ–≤–∏–π –∞—Ç—Ä–∏–±—É—Ç
            except Exception:
                raw_url = str(tag_or_none)								# üõü –Ø–∫—â–æ –µ–ª–µ–º–µ–Ω—Ç –Ω–µ —Ç–µ–≥ ‚Äî –±–µ—Ä–µ–º–æ str()

            normalized = _normalize_image_url(raw_url)					# üßº –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –∑–∞—Å—Ç–æ—Å–æ–≤—É—é—á–∏ –≥–ª–æ–±–∞–ª—å–Ω—ñ –ø—Ä–∞–≤–∏–ª–∞
            if normalized:
                logger.debug("üñºÔ∏è DOM —Å–µ–ª–µ–∫—Ç–æ—Ä '%s' –¥–∞–≤ –≥–æ–ª–æ–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.", selector)
                return normalized										# ‚úÖ –ó—É–ø–∏–Ω—è—î–º–æ—Å—è –Ω–∞ –ø–µ—Ä—à—ñ–π –≤–∞–ª—ñ–¥–Ω—ñ–π –∫–∞—Ä—Ç–∏–Ω—Ü—ñ

        logger.info("üñºÔ∏è –ì–æ–ª–æ–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return ""

    # ================================
    # üñºÔ∏è –£–°–Ü –ó–û–ë–†–ê–ñ–ï–ù–ù–Ø
    # ================================
    def extract_all_images(
        self,
        *,
        limit: Optional[int] = None,
        filter_small_images: bool = True,
    ) -> List[str]:
        """
        üñºÔ∏è –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ —É—Å—ñ—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å, –∑–±–µ—Ä—ñ–≥–∞—é—á–∏ –ø–æ—Ä—è–¥–æ–∫ —ñ –∑–∞—Å—Ç–æ—Å–æ–≤—É—é—á–∏ —Ñ—ñ–ª—å—Ç—Ä–∏.

        Args:
            limit (int | None): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤; None ‚Äî –±–µ–∑ –æ–±–º–µ–∂–µ–Ω–Ω—è.
            filter_small_images (bool): –ß–∏ –≤—ñ–¥—Å—ñ—é–≤–∞—Ç–∏ ¬´–º–∞–ª—ñ¬ª –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∑–∞ —Ä–æ–∑–º—ñ—Ä–æ–º.

        Returns:
            List[str]: –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ URL –∑–æ–±—Ä–∞–∂–µ–Ω—å.
        """
        filters = _ConfigSnapshot.img_filters()							# ‚öôÔ∏è –ó—á–∏—Ç—É—î–º–æ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó/ENV
        bad_tokens: Tuple[str, ...] = tuple(filters.get("bad_tokens", ()))		# üõë –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞, —è–∫—ñ –≤–∏–∫–ª—é—á–∞—é—Ç—å URL
        allowed_ext: Tuple[str, ...] = tuple(							# üîö –î–æ–∑–≤–æ–ª–µ–Ω—ñ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤
            filters.get("allowed_ext", (".jpg", ".jpeg", ".png", ".webp", ".avif"))
        )
        min_side = int(filters.get("min_side_px", 0) or 0)				# üìè –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ —Å—Ç–æ—Ä–æ–Ω–∞ –ø—Ä–µ–≤ º—é
        logger.debug(
            "üñºÔ∏è extract_all_images(limit=%s, filter_small=%s, min_side=%s).",
            limit,
            filter_small_images,
            min_side,
        )

        def _looks_like_product_img(url: str) -> bool:
            if not url:
                return False
            lower = url.lower()
            if not lower.endswith(allowed_ext):
                return False
            size_chart_tokens = (
                "sizechart",
                "size_chart",
                "size-chart",
                "size chart",
                "women-size-chart",
                "mens-size-chart",
            )
            if any(token in lower for token in size_chart_tokens):
                return True											# üìè Size-chart whitelist
            return not any(token in lower for token in bad_tokens)		# üö´ –í—ñ–¥—Å—ñ—é—î–º–æ favicon/sprite —Ç–∞ —ñ–Ω—à–∏–π —à—É–º

        def _probably_too_small(url: str) -> bool:
            lower = url.lower()
            match = re.search(											# üîé Shopify-—Å—É—Ñ—ñ–∫—Å–∏ "_400x400"
                r"_(\d+)(?:x(\d+))?(?=\.(?:jpe?g|png|webp|avif)(?:$|\?))",
                lower,
            )
            if match:
                width = int(match.group(1))
                height = int(match.group(2)) if match.group(2) else width
                return min(width, height) < min_side					# üìâ –ó–∞–º–∞–ª—ñ —Ä–æ–∑–º—ñ—Ä–∏

            match_width = re.search(r"/(?:w(?:idth)?[_-]?)(\d{1,4})/", lower)	# üîé –ú–∞—Ä–∫–µ—Ä–∏ /w400/ —É URL
            if match_width:
                side = int(match_width.group(1))
                return side < min_side									# üìâ –ó–∞–º–∞–ª–∞ —à–∏—Ä–∏–Ω–∞
            return False

        host = cast(_ImagesHost, self)									# üß≠ –î–∞—î –¥–æ—Å—Ç—É–ø –¥–æ soup/json-ld

        images: List[str] = []											# üì¶ –ù–∞–∫–æ–ø–∏—á—É—î–º–æ –≤—Å—ñ URL
        images.extend(host._images_from_json_ld())						# 1Ô∏è‚É£ –°–ø–µ—Ä—à—É –±–µ—Ä–µ–º–æ JSON-LD (–∑–∞–∑–≤–∏—á–∞–π –Ω–∞–π–ø–æ–≤–Ω—ñ—à–∏–π —Å–ø–∏—Å–æ–∫)
        logger.debug("üñºÔ∏è JSON-LD –ø–æ–≤–µ—Ä–Ω—É–≤ %d –∑–æ–±—Ä–∞–∂–µ–Ω—å.", len(images))

        for selector in self._S.ALL_IMAGES_LIST:						# 2Ô∏è‚É£ –î–∞–ª—ñ –ø—Ä–æ—á—ñ—Å—É—î–º–æ DOM —Å–µ–ª–µ–∫—Ç–æ—Ä –∑–∞ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º
            for element in host.soup.select(selector):					# üîÅ –ë–µ—Ä–µ–º–æ –∫–æ–∂–µ–Ω –∑–±—ñ–≥
                try:
                    tag = cast(Tag, element)							# üß± –û—á—ñ–∫—É—î–º–æ <img>/<source>
                    candidates = [										# üìã –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–∏ –¥–∂–µ—Ä–µ–ª URL
                        tag.get("src"),
                        tag.get("data-src"),
                        tag.get("data-original"),
                        self._attr_first(token=tag.get("srcset")),
                        self._attr_first(token=tag.get("data-srcset")),
                    ]
                    raw_url = next((str(value) for value in candidates if value), "")	# üéØ –ü–µ—Ä—à–∏–π –Ω–µ–Ω—É–ª—å–æ–≤–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç
                except Exception:
                    raw_url = str(element)								# üõü –Ø–∫—â–æ –µ–ª–µ–º–µ–Ω—Ç –Ω–µ —Ç–µ–≥ ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ str()

                normalized = self._normalize_img(raw_url or "")			# üßº –ö–∞–Ω–æ–Ω—ñ–∑—É—î–º–æ —Ç–∞ –æ–±—Ä—ñ–∑–∞—î–º–æ query
                if normalized:
                    images.append(normalized)							# ‚ûï –î–æ–¥–∞—î–º–æ —É –∑–∞–≥–∞–ª—å–Ω–∏–π —Å–ø–∏—Å–æ–∫

        deduplicated = list(uniq_keep_order(images))					# ‚ôªÔ∏è –ü—Ä–∏–±–∏—Ä–∞—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏, –∑–±–µ—Ä—ñ–≥–∞—é—á–∏ –ø–æ—Ä—è–¥–æ–∫
        logger.info(
            "üì∑ Raw image candidates | total=%d | samples=%s",
            len(deduplicated),
            deduplicated[:10],
        )
        if filter_small_images:
            filtered = [url for url in deduplicated if _looks_like_product_img(url)]	# ‚úÖ –õ–∏—à–∞—î–º–æ –ª–∏—à–µ –≤–∞–ª—ñ–¥–Ω—ñ URL
            filtered = [url for url in filtered if not _probably_too_small(url)]	# üìè –Ü –ø—Ä–∏–±–∏—Ä–∞—î–º–æ –¥—Ä—ñ–±–Ω—ñ –ø—Ä–µ–≤ º—é
        else:
            filtered = [url for url in deduplicated if _looks_like_product_img(url) or True]	# üîÅ –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π —Ñ—ñ–ª—å—Ç—Ä –ø–æ —Ç–æ–∫–µ–Ω–∞—Ö

        if isinstance(limit, int) and limit > 0:
            filtered = filtered[:limit]									# ‚úÇÔ∏è –ó–∞ –ø–æ—Ç—Ä–µ–±–∏ –æ–±—Ä—ñ–∑–∞—î–º–æ —Å–ø–∏—Å–æ–∫ –¥–æ –ª—ñ–º—ñ—Ç—É

        logger.info(
            "üì∑ Filtered product images | total=%d | samples=%s",
            len(filtered),
            filtered[:10],
        )
        return filtered													# üì¶ –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —á–∏—Å—Ç–∏–π —Å–ø–∏—Å–æ–∫ URL

    # ================================
    # üß∞ –î–û–ü–û–ú–Ü–ñ–ù–Ü –ú–ï–¢–û–î–ò
    # ================================
    @staticmethod
    def _attr_first(*, token: Any) -> Optional[str]:
        """
        üß∞ –ü–æ–≤–µ—Ä—Ç–∞—î –ø–µ—Ä—à–∏–π —Ä—è–¥–æ–∫ —ñ–∑ –∞—Ç—Ä–∏–±—É—Ç–∞ (—è–∫—â–æ –≤—ñ–Ω —Å–ø–∏—Å–æ–∫/–∫–æ—Ä—Ç–µ–∂) –∞–±–æ None.
        """
        if token is None:
            return None
        if isinstance(token, str):
            return token.split(" ")[0] if token else None				# üîó –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à–µ –∑–Ω–∞—á–µ–Ω–Ω—è –∑—ñ srcset
        if isinstance(token, (list, tuple)):
            for value in token:
                if value:
                    return str(value).split(" ")[0]
        return None
