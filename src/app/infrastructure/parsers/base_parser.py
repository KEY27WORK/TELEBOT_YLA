# üß† app/infrastructure/parsers/base_parser.py
"""
üß† base_parser.py ‚Äî –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –ø–∞—Ä—Å–∏–Ω–≥—É —Å—Ç–æ—Ä—ñ–Ω–∫–∏ —Ç–æ–≤–∞—Ä—É.

üîπ –ö–ª–∞—Å `BaseParser`:
- –†–µ–∞–ª—ñ–∑—É—î –ø–æ–≤–Ω–∏–π —Ü–∏–∫–ª –æ–±—Ä–æ–±–∫–∏ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä—É.
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –≤–ø—Ä–æ–≤–∞–¥–∂–µ–Ω—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ (WebDriver, Translator, Config).
- –î–µ–ª–µ–≥—É—î –≤–∏—Ç—è–≥ –¥–∞–Ω–∏—Ö –∑ HTML –∫–ª–∞—Å—É `HtmlDataExtractor`.
- –ú—ñ—Å—Ç–∏—Ç—å –ª–æ–≥—ñ–∫—É fallback –¥–ª—è stock —Ç–∞ –º–∞–ø–ø—ñ–Ω–≥ —Ä–æ–∑–º—ñ—Ä—ñ–≤.
- –ê–≥—Ä–µ–≥—É—î –¥–∞–Ω—ñ —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î –æ–±'—î–∫—Ç `ProductInfo`.
"""

# üåê –ó–æ–≤–Ω—ñ—à–Ω—ñ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏
from bs4 import BeautifulSoup           # üßΩ –ü–∞—Ä—Å–∏–Ω–≥ HTML
from rich.progress import (             # ‚è≥ –í–∏–≤—ñ–¥ –ø—Ä–æ–≥—Ä–µ—Å—É –≤ —Ç–µ—Ä–º—ñ–Ω–∞–ª
    Progress, SpinnerColumn,
    TextColumn, TimeElapsedColumn
    )            

# üî† –°–∏—Å—Ç–µ–º–Ω—ñ —ñ–º–ø–æ—Ä—Ç–∏
import logging                      # üßæ –õ–æ–≥—É–≤–∞–Ω–Ω—è
import re                           # üî§ –†–µ–≥—É–ª—è—Ä–Ω—ñ –≤–∏—Ä–∞–∑–∏
from typing import (                # üß∞ –¢–∏–ø—ñ–∑–∞—Ü—ñ—è
    Any, Dict, Optional                         
    )
# üß© –í–Ω—É—Ç—Ä—ñ—à–Ω—ñ –º–æ–¥—É–ª—ñ –ø—Ä–æ—î–∫—Ç—É
from app.config.config_service import ConfigService                             # ‚öôÔ∏è –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è (–≤–∫–ª—é—á–∞—é—á–∏ –≤–∞–≥–∏)
from app.domain.products.entities import ProductInfo                            # üì¶ –°—É—Ç–Ω—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—É
from app.domain.products.interfaces import IProductDataProvider                 # üß± –ö–æ–Ω—Ç—Ä–∞–∫—Ç –¥–ª—è –ø–∞—Ä—Å–µ—Ä—ñ–≤
from app.domain.products.services.weight_resolver import WeightResolver         # ‚öñÔ∏è –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –≤–∞–≥–∏
from app.infrastructure.ai.translator import TranslatorService                  # ü§ñ GPT-—Å–µ—Ä–≤—ñ—Å –¥–ª—è fallback –æ–ø–∏—Å—É
from app.infrastructure.web.webdriver_service import WebDriverService           # üåç –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è HTML-—Å—Ç–æ—Ä—ñ–Ω–∫–∏
from app.shared.utils.url_parser_service import UrlParserService                # üîó –°–µ—Ä–≤—ñ—Å –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ URL
from .html_data_extractor import HtmlDataExtractor                              # üï∑Ô∏è –í–∏—Ç—è–≥ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö


# ================================
# üèõÔ∏è –ì–û–õ–û–í–ù–ò–ô –ö–õ–ê–° –ü–ê–†–°–ï–†–ê
# ================================
class BaseParser(IProductDataProvider):
    """
    üì¶ –í—ñ–¥–ø–æ–≤—ñ–¥–∞—î –∑–∞ –ø–æ–≤–Ω–∏–π —Ü–∏–∫–ª –æ–±—Ä–æ–±–∫–∏ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ —Ç–æ–≤–∞—Ä—É YoungLA:
    –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è ‚Üí –≤–∏—Ç—è–≥ –¥–∞–Ω–∏—Ö ‚Üí –æ–±—Ä–æ–±–∫–∞ ‚Üí —Ñ–æ—Ä–º—É–≤–∞–Ω–Ω—è ProductInfo.
    """

    # ================================
    # ‚öôÔ∏è –Ü–ù–Ü–¶–Ü–ê–õ–Ü–ó–ê–¶–Ü–Ø
    # ================================
    def __init__(
        self,
        url: str,
        webdriver_service: WebDriverService,
        translator_service: TranslatorService,
        config_service: ConfigService,
        weight_resolver: WeightResolver,
        url_parser_service: UrlParserService,
        enable_progress: bool = True,
    ):
        self.url = url													            # üîó URL —Å—Ç–æ—Ä—ñ–Ω–∫–∏ —Ç–æ–≤–∞—Ä—É
        self.webdriver_service = webdriver_service									# üåç –°–µ—Ä–≤—ñ—Å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è HTML
        self.translator_service = translator_service								# ü§ñ –ü–µ—Ä–µ–∫–ª–∞–¥–∞—á –¥–ª—è fallback –æ–ø–∏—Å—ñ–≤
        self.config_service = config_service										# ‚öôÔ∏è –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –¥–ª—è user-agent)
        self.weight_resolver = weight_resolver									    # ‚öñÔ∏è –°–µ—Ä–≤—ñ—Å –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –≤–∞–≥–∏ —Ç–æ–≤–∞—Ä—É
        self.url_parser_service = url_parser_service
        self.enable_progress = enable_progress									    # ‚è≥ –í–∫–ª—é—á–∏—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä –≤ —Ç–µ—Ä–º—ñ–Ω–∞–ª—ñ

        self._currency = self.url_parser_service.get_currency(url)					# üí± –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤–∞–ª—é—Ç–∏ –∑–∞ URL (us/eu/uk)

        self.page_source: Optional[str] = None									    # üìÑ HTML-–∫–æ–¥ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ —è–∫ —Å–∏—Ä–∏–π —Ç–µ–∫—Å—Ç
        self._page_soup: Optional[BeautifulSoup] = None							    # üßΩ –ü–∞—Ä—Å–µ–Ω–µ –¥–µ—Ä–µ–≤–æ DOM –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É

    # ================================
    # üîÑ –ü–£–ë–õ–Ü–ß–ù–ò–ô –Ü–ù–¢–ï–†–§–ï–ô–°
    # ================================
    async def get_product_info(self) -> ProductInfo:
        """
        üîÑ –û—Å–Ω–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥: –∑–∞–ø—É—Å–∫–∞—î –ø–æ–≤–Ω–∏–π –ø–∞–π–ø–ª–∞–π–Ω —ñ –ø–æ–≤–µ—Ä—Ç–∞—î ProductInfo.
        """
        try:
            await self._fetch_and_prepare_soup()								        # üåç –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏ —Ç–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è soup-–¥–µ—Ä–µ–≤–∞
            if not self._page_soup:
                raise ConnectionError(
                    "–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∞–±–æ —Ä–æ–∑–ø–∞—Ä—Å–∏—Ç–∏ HTML."
                    )

            extractor = HtmlDataExtractor(self._page_soup)						        # üï∑Ô∏è –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ –¥–ª—è –≤–∏—Ç—è–≥—É –¥–∞–Ω–∏—Ö –∑ DOM
            data = self._extract_raw_data(extractor)							        # üì• –í–∏—Ç—è–≥ —Å–∏—Ä–∏—Ö –¥–∞–Ω–∏—Ö (title, price, description —Ç–æ—â–æ)
            processed_data = await self._process_data(data)						        # ‚ú® –û–±—Ä–æ–±–∫–∞: fallback + –≤–∞–≥–∞
            return self._build_product_info(processed_data)						        # üèóÔ∏è –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç–∞ ProductInfo

        except Exception as e:
            logging.exception(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥—É {self.url}: {e}")
            return ProductInfo(
                title="–ü–æ–º–∏–ª–∫–∞", price=0.0, description="–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–∞–Ω—ñ"
                )
        
    # ================================
    # üß± –î–û–ü–û–ú–Ü–ñ–ù–Ü –ü–†–ò–í–ê–¢–ù–Ü –ú–ï–¢–û–î–ò
    # ================================
    async def _fetch_and_prepare_soup(self) -> None:
        """
        üåê –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î HTML-—Å—Ç–æ—Ä—ñ–Ω–∫—É —ñ —Å—Ç–≤–æ—Ä—é—î BeautifulSoup –¥–µ—Ä–µ–≤–æ.
        """
        logging.info(f"üåç –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {self.url}...")										    # üßæ –õ–æ–≥ –ø—Ä–æ –ø–æ—á–∞—Ç–æ–∫ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        task_description = f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è [cyan]{self.url.split('/')[-1]}[/cyan]..."			# üìù –û–ø–∏—Å –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä—É

        if self.enable_progress:
            with Progress(SpinnerColumn(),
                    TextColumn("[progress.description]{task.description}"),
                    TimeElapsedColumn(), transient=True
                    ) as progress:

                progress.add_task(description=task_description, total=None)							# ‚è≥ –î–æ–¥–∞—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è –¥–æ –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä–∞
                self.page_source = await self.webdriver_service.fetch_page_source(self.url)			# üåê –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è HTML —á–µ—Ä–µ–∑ WebDriver

        else:
            self.page_source = await self.webdriver_service.fetch_page_source(self.url)				# üåê –ë–µ–∑ –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä–∞

        if self.page_source:
            self._page_soup = BeautifulSoup(self.page_source, "html.parser")						# üßΩ –ü–∞—Ä—Å–∏–Ω–≥ HTML —É DOM-–¥–µ—Ä–µ–≤–æ
            logging.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ ({len(self.page_source)} –±–∞–π—Ç).")						    # üßæ –õ–æ–≥ –ø—Ä–æ —É—Å–ø—ñ—à–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        else:
            logging.error(f"‚ùå –ù–µ–º–æ–∂–ª–∏–≤–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏: {self.url}")								    # ‚ùó –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ

    def _extract_raw_data(self, extractor: HtmlDataExtractor) -> Dict[str, Any]:
        """
        üì• –í–∏—Ç—è–≥—É—î —É—Å—ñ —Å–∏—Ä—ñ –¥–∞–Ω—ñ –∑ DOM-–¥–µ—Ä–µ–≤–∞.
        """
        return {
            "title": extractor.extract_title(),												        # üè∑Ô∏è –ù–∞–∑–≤–∞ —Ç–æ–≤–∞—Ä—É
            "price": extractor.extract_price(),												        # üí∞ –¶—ñ–Ω–∞
            "description": extractor.extract_description(),									        # üìù –û–ø–∏—Å —Ç–æ–≤–∞—Ä—É
            "main_image": extractor.extract_main_image(),									        # üñºÔ∏è –ì–æ–ª–æ–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            "all_images": extractor.extract_all_images(),									        # üñºÔ∏èüìÅ –í—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            "sections": extractor.extract_detailed_sections(),								        # üìö –ë–ª–æ–∫–∏ –æ–ø–∏—Å—É
            "stock_data": self._get_stock_with_fallback(extractor),							        # üóÉÔ∏è –î–∞–Ω—ñ –ø—Ä–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å (stock)
        }

    async def _process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ‚ú® –û–±—Ä–æ–±–ª—è—î —Å–∏—Ä—ñ –¥–∞–Ω—ñ: fallback –æ–ø–∏—Å—É + –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –≤–∞–≥–∏.
        """
        if data.get("description") and len(data["description"].strip()) < 20:						# üßê –Ø–∫—â–æ –æ–ø–∏—Å –∑–∞–Ω–∞–¥—Ç–æ –∫–æ—Ä–æ—Ç–∫–∏–π
            first_key = next(iter(data.get("sections", {})), None)
            if first_key:
                data["description"] = data["sections"][first_key]								    # üîÅ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–µ—Ä—à–∏–π –±–ª–æ–∫ —è–∫ –æ–ø–∏—Å

        title = data.get("title", "")
        description = data.get("description", "")
        image_url = data.get("main_image", "")
        data["weight"] = await self.weight_resolver.resolve(title, description, image_url)		    # ‚öñÔ∏è AI-–æ—Ü—ñ–Ω–∫–∞ –≤–∞–≥–∏ —Ç–æ–≤–∞—Ä—É

        return data

    def _build_product_info(self, data: Dict[str, Any]) -> ProductInfo:
        """
        üèóÔ∏è –ó–±–∏—Ä–∞—î –æ—Å—Ç–∞—Ç–æ—á–Ω–∏–π –æ–±'—î–∫—Ç ProductInfo –∑ –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö.
        """
        stock_data = data.get("stock_data", {})
        if stock_data:
            stock_data = self._map_stock_sizes(stock_data)										    # üîÑ –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –Ω–∞–∑–≤ —Ä–æ–∑–º—ñ—Ä—ñ–≤

        return ProductInfo(
            title=data.get("title", "–ù–µ–≤—ñ–¥–æ–º–æ"),											        # üè∑Ô∏è –ù–∞–∑–≤–∞
            price=float(data.get("price", 0.0)),											        # üí∞ –¶—ñ–Ω–∞
            description=data.get("description", ""),										        # üìù –û–ø–∏—Å
            image_url=data.get("main_image", ""),										            # üñºÔ∏è –ì–æ–ª–æ–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            weight=float(data.get("weight", 0.0)),										            # ‚öñÔ∏è –í–∞–≥–∞
            images=data.get("all_images", []),											            # üñºÔ∏èüìÅ –í—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            currency=self._currency,														        # üí± –í–∞–ª—é—Ç–∞ (–≤–∏–∑–Ω–∞—á–µ–Ω–∞ –∑ URL)
            sections=data.get("sections", {}),											            # üìö –î–µ—Ç–∞–ª—å–Ω—ñ –±–ª–æ–∫–∏ –æ–ø–∏—Å—É
            stock_data=stock_data,														            # üóÉÔ∏è –ù–∞—è–≤–Ω—ñ—Å—Ç—å –ø–æ –∫–æ–ª—å–æ—Ä–∞—Ö —ñ —Ä–æ–∑–º—ñ—Ä–∞—Ö
        )

    # ================================
    # üì¶ –û–ë–†–û–ë–ö–ê –ù–ê–Ø–í–ù–û–°–¢–Ü
    # ================================
    def _get_stock_with_fallback(self, extractor: HtmlDataExtractor) -> Dict[str, Dict[str, bool]]:
        """
        üóÉÔ∏è –í–∏—Ç—è–≥—É—î –Ω–∞—è–≤–Ω—ñ—Å—Ç—å —ñ–∑ JSON-LD –∞–±–æ legacy DOM.
        """
        return extractor.extract_stock_from_json_ld() or extractor.extract_stock_from_legacy() or {}	# üîÅ Fallback –ª–æ–≥—ñ–∫–∞

    def _map_stock_sizes(self, stock_data: Dict[str, Dict[str, bool]]) -> Dict[str, Dict[str, bool]]:
        """
        üîÑ –ü—Ä–∏–≤–æ–¥–∏—Ç—å —Å–∏—Ä—ñ —Ä–æ–∑–º—ñ—Ä–∏ –¥–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç—É ("XSmall" ‚Üí "XS").
        """
        return {
            color: {
                self._map_size(size): available												# ‚ÜîÔ∏è –ú–∞–ø—ñ–Ω–≥ –∫–æ–∂–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É
                for size, available in sizes.items()
            }
            for color, sizes in stock_data.items()
        }

    def _map_size(self, raw_size: str) -> str:
        """
        üî§ –ú–∞–ø–ø—ñ–Ω–≥ –æ–¥–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É —É –∫–æ—Ä–æ—Ç–∫–∏–π –≤–∏–≥–ª—è–¥.
        """
        size_mapping = {
            "XXSmall": "XXS", "XSmall": "XS", "Small": "S", "Medium": "M",
            "Large": "L", "XLarge": "XL", "XXLarge": "XXL", "XXXLarge": "XXXL"
        }
        clean_size = re.sub(r"[^a-zA-Z]", "", raw_size)									    # üßπ –í–∏–¥–∞–ª—è—î–º–æ –∑–∞–π–≤—ñ —Å–∏–º–≤–æ–ª–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –ø—Ä–æ–±—ñ–ª–∏)
        return size_mapping.get(clean_size, clean_size)										# üß≠ –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –º–∞–ø—ñ–Ω–≥ –∞–±–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª