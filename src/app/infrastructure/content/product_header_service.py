# üß† app/infrastructure/content/product_header_service.py
"""
üß† –§–æ—Ä–º—É—î –ª–µ–≥–∫—ñ ¬´–∑–∞–≥–æ–ª–æ–≤–∫–∏¬ª —Ç–æ–≤–∞—Ä—ñ–≤ (title + –≥–æ–ª–æ–≤–Ω–µ —Ñ–æ—Ç–æ + canonical URL) –±–µ–∑ –ø–æ–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞.

üîπ `ProductHeaderService` –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î `ParserFactory` —Ç–∞ `HtmlDataExtractor`, —â–æ–± —à–≤–∏–¥–∫–æ –≤–∏—Ç—è–≥–Ω—É—Ç–∏ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –Ω–∞–±—ñ—Ä –¥–∞–Ω–∏—Ö.  
üîπ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è –ø—Ä–µ–≤ º—é/–∫–∞—Ä—É—Å–µ–ª–µ–π, –¥–µ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–∞ –ø–æ–≤–Ω–∞ –∞–≥—Ä–µ–≥–∞—Ü—ñ—è –∫–æ–Ω—Ç–µ–Ω—Ç—É.  
üîπ –ú–∞—î best-effort –ø–æ–≤–µ–¥–µ–Ω–∏–µ: –ø–æ–≤–µ—Ä—Ç–∞—î –∑–∞–≥–ª—É—à–∫—É, —è–∫—â–æ –¥–∞–Ω—ñ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ, –∞–ª–µ –ª–æ–≥—É—î –∫–æ–Ω—Ç–µ–∫—Å—Ç.
"""

from __future__ import annotations

# üî† –°–∏—Å—Ç–µ–º–Ω—ñ —ñ–º–ø–æ—Ä—Ç–∏
import logging                                                      # üßæ –õ–æ–≥—É–≤–∞–Ω–Ω—è –∂–∏—Ç—Ç—î–≤–æ–≥–æ —Ü–∏–∫–ª—É
from dataclasses import dataclass                                    # üì¶ DTO –∑–∞–≥–æ–ª–æ–≤–∫–∞
from typing import Optional, TYPE_CHECKING                           # üìê –¢–∏–ø—ñ–∑–∞—Ü—ñ—è

# üß© –í–Ω—É—Ç—Ä—ñ—à–Ω—ñ –º–æ–¥—É–ª—ñ –ø—Ä–æ—î–∫—Ç—É
from app.infrastructure.parsers.html_data_extractor import HtmlDataExtractor  # üßæ –í–∏—Ç—è–≥ HTML
from app.infrastructure.parsers.parser_factory import ParserFactory            # üèóÔ∏è –§–∞–±—Ä–∏–∫–∞ –ø–∞—Ä—Å–µ—Ä—ñ–≤
from app.shared.utils.logger import LOG_NAME                                   # üè∑Ô∏è –Ü–º º—è –ª–æ–≥–µ—Ä–∞
from app.shared.utils.url_parser_service import UrlParserService              # üîó –ü–æ–±—É–¥–æ–≤–∞ URL

if TYPE_CHECKING:                                                             # üß† –ü—ñ–¥–∫–∞–∑–∫–∏ –ª–∏—à–µ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
    from app.infrastructure.parsers.base_parser import BaseParser             # type: ignore

logger = logging.getLogger(LOG_NAME)                                          # üßæ –ú–æ–¥—É–ª—å–Ω–∏–π –ª–æ–≥–µ—Ä


# ================================
# üì¶ DTO-–ó–ê–ì–û–õ–û–í–û–ö
# ================================
@dataclass(frozen=True)
class ProductHeaderDTO:
    """üì¶ –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –Ω–∞–±—ñ—Ä –¥–∞–Ω–∏—Ö: –Ω–∞–∑–≤–∞, –≥–æ–ª–æ–≤–Ω–∏–π –∫–∞–¥—Ä, –∫–∞–Ω–æ–Ω—ñ—á–Ω–∏–π URL."""

    title: str                                                              # üè∑Ô∏è –ù–∞–∑–≤–∞ (—É –≤–µ—Ä—Ö–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ)
    image_url: Optional[str]                                                # üñºÔ∏è URL –≥–æ–ª–æ–≤–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
    product_url: str                                                        # üîó –ö–∞–Ω–æ–Ω—ñ—á–Ω–∏–π URL —Ç–æ–≤–∞—Ä—É


__all__ = ["ProductHeaderService", "ProductHeaderDTO"]


# ================================
# üèõÔ∏è –°–ï–†–í–Ü–° –ü–û–ë–£–î–û–í–ò –ó–ê–ì–û–õ–û–í–ö–Ü–í
# ================================
class ProductHeaderService:
    """üèõÔ∏è –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω–æ –≤–∏—Ç—è–≥—É—î –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –Ω–∞–±—ñ—Ä –¥–∞–Ω–∏—Ö —Ç–æ–≤–∞—Ä—É."""

    def __init__(
        self,
        parser_factory: ParserFactory,
        url_parser_service: UrlParserService,
    ) -> None:
        self._parser_factory = parser_factory                                # üèóÔ∏è –§–∞–±—Ä–∏–∫–∞ –ø–∞—Ä—Å–µ—Ä—ñ–≤
        self._url_parser = url_parser_service                                # üîó –°–µ—Ä–≤—ñ—Å –ø–æ–±—É–¥–æ–≤–∏ URL
        logger.debug("‚öôÔ∏è ProductHeaderService init (parser_factory=%s)", parser_factory)

    async def create_header(self, product_path: str, region: str = "us") -> Optional[ProductHeaderDTO]:
        """üîÑ –§–æ—Ä–º—É—î DTO —ñ–∑ title/image/url –∞–±–æ –ø–æ–≤–µ—Ä—Ç–∞—î None —É —Ä–∞–∑—ñ —Ñ–∞—Ç–∞–ª—å–Ω–æ—ó –ø–æ–º–∏–ª–∫–∏."""
        url = self._url_parser.build_product_url(region, product_path)       # üåê –ë—É–¥—É—î–º–æ –∫–∞–Ω–æ–Ω—ñ—á–Ω–∏–π URL
        if not url:
            logger.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø–æ–±—É–¥—É–≤–∞—Ç–∏ URL (region=%s, path=%s)", region, product_path)
            return None

        logger.info("üè∑Ô∏è –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–ª—è: %s", url)

        try:
            parser = self._parser_factory.create_product_parser(             # üßµ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –ø–∞—Ä—Å–µ—Ä
                url,
                enable_progress=False,
            )

            await parser._fetch_and_prepare_soup()  # type: ignore[attr-defined]  # ‚ö†Ô∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø—Ä–∏–≤–∞—Ç–Ω–∏–π API (—Ç–∏–º—á–∞—Å–æ–≤–æ)
            soup = getattr(parser, "_page_soup", None)                       # type: ignore[attr-defined]
            if soup is None:
                raise ConnectionError("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ HTML –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞.")

            extractor = HtmlDataExtractor(soup)                               # üßæ –õ–µ–≥–∫–æ–≤–∞–≥–æ–≤–∏–π –µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
            title = extractor.extract_title()                       # üè∑Ô∏è –í–∏—Ç—è–≥—É—î–º–æ –Ω–∞–∑–≤—É –∑—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏
            image_url = extractor.extract_main_image()               # üñºÔ∏è –ë–µ—Ä–µ–º–æ –≥–æ–ª–æ–≤–Ω–∏–π –∫–∞–¥—Ä
            logger.debug("üîç Header extractor: title=%r image=%r", title, image_url)

            if not title or "–ø–æ–º–∏–ª–∫–∞" in title.lower() or "–±–µ–∑ –Ω–∞–∑–≤–∏" in title.lower():
                logger.warning("‚ö†Ô∏è –ù–µ–≤–∞–ª—ñ–¥–Ω–∏–π title –¥–ª—è %s: %r", url, title)
                return ProductHeaderDTO(title="üîó –¢–û–í–ê–†", image_url=None, product_url=url)

            normalized_title = title.upper()                         # üî† –£–Ω—ñ—Ñ—ñ–∫—É—î–º–æ —Ä–µ–≥—ñ—Å—Ç—Ä –¥–ª—è UI
            return ProductHeaderDTO(title=normalized_title, image_url=image_url, product_url=url)

        except Exception as exc:  # noqa: BLE001
            logger.exception("üî• –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∞ (%s): %s", product_path, exc)
            return ProductHeaderDTO(title="üîó –¢–û–í–ê–†", image_url=None, product_url=url)  # üõ°Ô∏è –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –∑–∞–≥–ª—É—à–∫—É
