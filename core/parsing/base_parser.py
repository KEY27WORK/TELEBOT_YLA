""" üß† base_parser.py ‚Äî –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω–∏–π –±–∞–∑–æ–≤–∏–π –∫–ª–∞—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É —Å—Ç–æ—Ä—ñ–Ω–æ–∫ —Ç–æ–≤–∞—Ä—ñ–≤ YoungLA.

üîπ –ö–ª–∞—Å `BaseParser`:
- –í–∏–∑–Ω–∞—á–∞—î –±–∞–∑–æ–≤—ñ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ñ –º–µ—Ç–æ–¥–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É —Å—Ç–æ—Ä—ñ–Ω–æ–∫
- –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î HTML —á–µ—Ä–µ–∑ Selenium WebDriver
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î BeautifulSoup –¥–ª—è –æ–±—Ä–æ–±–∫–∏ DOM
- –í–∏—Ç—è–≥—É—î —Ü—ñ–Ω—É, –æ–ø–∏—Å, –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è, —Ä–æ–∑–º—ñ—Ä–∏, –≤–∞–≥—É

–ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ:
- abc, re, logging, asyncio, json, time
- BeautifulSoup
- WebDriverService (Selenium)
- ConfigService (–≤–∞–≥–∞)
- TranslatorService (–≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –≤–∞–≥–∏ —á–µ—Ä–µ–∑ GPT)
"""

# üì¶ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ñ
import re
import time
import json
import logging
import asyncio
from abc import ABC, abstractmethod
from typing import Dict, Any

# üåê –ü–∞—Ä—Å–∏–Ω–≥ HTML
from bs4 import BeautifulSoup

# üß± –°–µ—Ä–≤—ñ—Å–∏
from core.webdriver.webdriver_service import WebDriverService
from core.config.config_service import ConfigService
from bot.content.translator import TranslatorService


class BaseParser(ABC):
    """üß† –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω–∏–π –±–∞–∑–æ–≤–∏–π –∫–ª–∞—Å –¥–ª—è –≤—Å—ñ—Ö —Ç–æ–≤–∞—Ä–Ω–∏—Ö –ø–∞—Ä—Å–µ—Ä—ñ–≤ YoungLA."""

    def __init__(self, url: str, currency_service: Any):
        """
        :param url: –ü–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫—É —Ç–æ–≤–∞—Ä—É
        :param currency_service: (–Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è, –∑–∞–ª–∏—à–µ–Ω–æ –¥–ª—è —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ)
        """
        self.url = url
        self.currency_service = currency_service
        self.page_source = None
        self.soup = None
        self.config = ConfigService()
        self.translator = TranslatorService()

    async def fetch_page(self, retries: int = 5) -> bool:
        """üåê –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î HTML-–∫–æ–¥ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ —á–µ—Ä–µ–∑ WebDriverService."""
        self.page_source = None
        start_time = time.time()

        for attempt in range(1, retries + 1):
            self.page_source = await WebDriverService().fetch_page_source(self.url)

            if self.page_source:
                self.soup = BeautifulSoup(self.page_source, "html.parser")
                logging.info(f"‚úÖ –°—Ç–æ—Ä—ñ–Ω–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {self.url}")
                logging.info(f"‚è≥ –ß–∞—Å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {time.time() - start_time:.2f} —Å–µ–∫.")
                return True
            
            title_tag = self.soup.find("h1")
            page_not_found = "Page Not Found" in self.page_source or "Your connection needs to be verified" in self.page_source
            
            if not title_tag or page_not_found:
                logging.warning(f"‚ö†Ô∏è –ü—ñ–¥–æ–∑—Ä—ñ–ª–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ (–Ω–µ–º–∞—î h1 –∞–±–æ Cloudflare-–∑–∞–≥–ª—É—à–∫–∞): —Å–ø—Ä–æ–±–∞ {attempt}")
                await asyncio.sleep(2)
                continue

            logging.warning(f"üîÑ –°–ø—Ä–æ–±–∞ {attempt}: –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É...")
            await asyncio.sleep(2)

        logging.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É: {self.url}")
        return False

    def _map_size(self, raw_size: str) -> str:
        """üéØ –ü—Ä–∏–≤–æ–¥–∏—Ç—å —Ä–æ–∑–º—ñ—Ä–∏ –¥–æ —Å–∫–æ—Ä–æ—á–µ–Ω–∏—Ö –ø–æ–∑–Ω–∞—á–µ–Ω—å (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, Medium ‚Üí M)."""
        size_mapping = {
            "XXSmall": "XXS", "XSmall": "XS", "Small": "S", "Medium": "M",
            "Large": "L", "XLarge": "XL", "XXLarge": "XXL", "XXXLarge": "XXXL"
        }
        clean = re.sub(r'[^a-zA-Z]', '', raw_size)
        return size_mapping.get(clean, clean)

    async def extract_title(self) -> str:
        """üìù –í–∏—Ç—è–≥—É—î –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–æ–≤–∞—Ä—É (h1)."""
        title_tag = self.soup.find("h1")
        return title_tag.text.strip() if title_tag else "–ë–µ–∑ –Ω–∞–∑–≤–∏"

    async def extract_price(self) -> float:
        """üí≤ –í–∏—Ç—è–≥—É—î —Ü—ñ–Ω—É –∑ –º–µ—Ç–∞-—Ç–µ–≥—É."""
        meta = self.soup.find("meta", {"property": "product:price:amount"})
        if meta:
            try:
                return float(meta["content"].replace(",", "."))
            except ValueError:
                logging.warning(f"‚ö†Ô∏è –ù–µ–º–æ–∂–ª–∏–≤–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ —Ü—ñ–Ω—É: {meta['content']}")
        return 0.0

    async def extract_description(self) -> str:
        """üßæ –í–∏—Ç—è–≥—É—î –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å —Ç–æ–≤–∞—Ä—É –∑ Twitter –º–µ—Ç–∞-—Ç–µ–≥—É."""
        meta = self.soup.find("meta", {"name": "twitter:description"})
        return meta["content"] if meta else "–û–ø–∏—Å –≤—ñ–¥—Å—É—Ç–Ω—ñ–π"

    async def extract_image(self) -> str:
        """üñºÔ∏è –í–∏—Ç—è–≥—É—î –≥–æ–ª–æ–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ og:image."""
        meta = self.soup.find("meta", {"property": "og:image"})
        return meta["content"] if meta else "–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤—ñ–¥—Å—É—Ç–Ω—î"

    async def extract_all_images(self) -> list[str]:
        """üñºÔ∏è –í–∏—Ç—è–≥—É—î –≤—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –≥–∞–ª–µ—Ä–µ—ó —Ç–æ–≤–∞—Ä—É."""
        images = []
        gallery = self.soup.select_one(".product-gallery__thumbnail-list")
        if gallery:
            for img in gallery.select("button img[src]"):
                url = img["src"]
                if url.startswith("//"):
                    url = "https:" + url
                images.append(url)
                logging.info(f"üì∏ –ó–Ω–∞–π–¥–µ–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {url}")
        return images

    async def format_colors_sizes(self, colors_sizes: dict) -> str:
        """üé® –§–æ—Ä–º–∞—Ç—É—î —Å–ª–æ–≤–Ω–∏–∫ {–∫–æ–ª—ñ—Ä: [—Ä–æ–∑–º—ñ—Ä–∏]} —É —Å–ø–∏—Å–æ–∫ –¥–ª—è Telegram."""
        if not colors_sizes:
            return "‚ùå –î–∞–Ω—ñ –ø—Ä–æ –∫–æ–ª—å–æ—Ä–∏ —Ç–∞ —Ä–æ–∑–º—ñ—Ä–∏ –≤—ñ–¥—Å—É—Ç–Ω—ñ."

        lines = []
        for color, sizes in colors_sizes.items():
            if sizes:
                line = f"‚Ä¢ {color}: {', '.join(sizes)}"
            else:
                line = f"‚Ä¢ {color}"
            lines.append(line)

        return "\n".join(lines)


    async def extract_colors_from_html(self) -> list[str]:
        """
        üé® –í–∏—Ç—è–≥—É—î —Å–ø–∏—Å–æ–∫ –∫–æ–ª—å–æ—Ä—ñ–≤ –∑ HTML (–Ω–µ —á–µ—Ä–µ–∑ JSON-LD).
    
        :return: –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤ –∫–æ–ª—å–æ—Ä—ñ–≤
        """
        colors = []
        swatch_block = self.soup.find("div", class_="product-form__swatch color")
        if not swatch_block:
            return colors
    
        inputs = swatch_block.find_all("input", {"name": "Color"})
        for input_tag in inputs:
            color_name = input_tag.get("value", "").strip()
            if color_name:
                colors.append(color_name)
    
        return colors
    
    async def extract_colors_sizes(self) -> dict:
        """
        üéØ –í–∏—Ç—è–≥—É—î –∫–∞—Ä—Ç—É –∫–æ–ª—å–æ—Ä—ñ–≤ —ñ —Ä–æ–∑–º—ñ—Ä—ñ–≤ –±–µ–∑ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ.
        –Ø–∫—â–æ –Ω–µ–º–∞—î –ø–æ–≤–Ω–∏—Ö –¥–∞–Ω–∏—Ö ‚Äî –ø—ñ–¥—Ç—è–≥—É—î –∫–æ–ª—å–æ—Ä–∏ –∑ HTML.
    
        :return: –°–ª–æ–≤–Ω–∏–∫ {–∫–æ–ª—ñ—Ä: [—Ä–æ–∑–º—ñ—Ä–∏]} –∞–±–æ –ø—Ä–æ—Å—Ç–æ {–∫–æ–ª—ñ—Ä: []}
        """
        color_size_map = {}
    
        # üß† 1. –°–ø—Ä–æ–±–∞ –≤–∏—Ç—è–≥—Ç–∏ –∫–æ–ª—å–æ—Ä–∏/—Ä–æ–∑–º—ñ—Ä–∏ —á–µ—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç
        color_blocks = self.soup.select('.variant-picker__option label.color-swatch span')
        if color_blocks:
            for block in color_blocks:
                color = block.get_text(strip=True)
                if color:
                    color_size_map[color] = []
    
            size_blocks = self.soup.select('.variant-picker__option label.block-swatch span')
            raw_sizes = [size.get_text(strip=True) for size in size_blocks if size.get_text(strip=True)]
            clean_sizes = [self._map_size(size) for size in raw_sizes]
    
            for color in color_size_map:
                color_size_map[color] = clean_sizes
    
        # üõ† 2. –Ø–∫—â–æ –∫–æ–ª—å–æ—Ä—ñ–≤ —á–µ—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π —à–ª—è—Ö –Ω–µ–º–∞—î ‚Äî –ø—Ä–æ–±—É—î–º–æ —á–µ—Ä–µ–∑ HTML
        if not color_size_map:
            colors = await self.extract_colors_from_html()
            if colors:
                color_size_map = {color: [] for color in colors}
    
        logging.info(f"üì¶ –ö–∞—Ä—Ç–∞ –∫–æ–ª—å–æ—Ä—ñ–≤/—Ä–æ–∑–º—ñ—Ä—ñ–≤ (–∑ HTML fallback): {color_size_map}")
        return color_size_map
    

    async def extract_color_size_availability(self) -> dict:
        """üìä –í–∏—Ç—è–≥—É—î –¥–∞–Ω—ñ –ø—Ä–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –∫–æ–∂–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É –≤ –∫–æ–∂–Ω–æ–º—É –∫–æ–ª—å–æ—Ä—ñ –∑ JSON-LD."""
        stock = {}
        for script in self.soup.find_all("script", {"type": "application/ld+json"}):
            try:
                data = json.loads(script.string)
                if isinstance(data, dict) and data.get("@type") == "Product" and "offers" in data:
                    for offer in data["offers"]:
                        name = offer.get("name", "")
                        available = "InStock" in offer.get("availability", "")
                        if " / " in name:
                            color, size = name.split(" / ")
                            color = color.strip()
                            size = self._map_size(size.strip())
                            stock.setdefault(color, {})[size] = available
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è JSON-LD parsing error: {e}")
        return stock

    async def determine_weight(self, title: str, description: str, image_url: str) -> float:
        """‚öñÔ∏è –í–∏–∑–Ω–∞—á–∞—î –≤–∞–≥—É —Ç–æ–≤–∞—Ä—É: —Å–ø–æ—á–∞—Ç–∫—É –∑ config, —ñ–Ω–∞–∫—à–µ ‚Äî —á–µ—Ä–µ–∑ GPT."""
        weight_data = self.config.load_weight_data()
        weight = next((w for k, w in weight_data.items() if k in title.lower()), None)

        if weight is None:
            logging.info(f"ü§ñ –í–∏–∑–Ω–∞—á–∞—î–º–æ –≤–∞–≥—É —á–µ—Ä–µ–∑ GPT –¥–ª—è: {title}")
            weight = self.translator.get_weight_estimate(title, description, image_url)
            self.config.update_weight_dict(title.lower(), weight)

        logging.info(f"‚úÖ –í–∏–∑–Ω–∞—á–µ–Ω–∞ –≤–∞–≥–∞: {weight} –∫–≥")
        return weight

    @abstractmethod
    async def parse(self) -> Dict[str, Any]:
        """üîß –ú–µ—Ç–æ–¥, —è–∫–∏–π –º–∞—î —Ä–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –¥–æ—á—ñ—Ä–Ω—ñ–π –ø–∞—Ä—Å–µ—Ä."""
        pass
