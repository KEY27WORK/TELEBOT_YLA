# üìè src/app/shared/utils/size_norm.py
"""
üìè size_norm.py ‚Äî –∑–∞–±–µ–∑–ø–µ—á—É—î —É–Ω—ñ—Ñ—ñ–∫–æ–≤–∞–Ω—É –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—é —Ç–æ–∫–µ–Ω—ñ–≤ —Ä–æ–∑–º—ñ—Ä—ñ–≤.

üîπ –ü—Ä–∏–≤–æ–¥–∏—Ç—å —á–∏—Å–ª–æ–≤—ñ —Ç–∞ –ª—ñ—Ç–µ—Ä–∞–ª—å–Ω—ñ —Ä–æ–∑–º—ñ—Ä–∏ –¥–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –≤–∏–≥–ª—è–¥—É.
üîπ –ü—ñ–¥—Ç—Ä–∏–º—É—î –∫–∏—Ä–∏–ª–∏—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ¬´—Öl¬ª ‚Üí ¬´XL¬ª).
üîπ –Ü–Ω—Ç–µ–≥—Ä—É—î aliases –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –¥–ª—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö —Å–∏–Ω–æ–Ω—ñ–º—ñ–≤.
"""

from __future__ import annotations

# üåê –ó–æ–≤–Ω—ñ—à–Ω—ñ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏
import re                                                   # üß™ –†–µ–≥—É–ª—è—Ä–Ω—ñ –≤–∏—Ä–∞–∑–∏ –¥–ª—è –æ—á–∏—â–µ–Ω–Ω—è

# üî† –°–∏—Å—Ç–µ–º–Ω—ñ —ñ–º–ø–æ—Ä—Ç–∏
from typing import Dict, Mapping, Optional                  # üß∞ –¢–∏–ø—ñ–∑–∞—Ü—ñ—è —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–∏—Ö

# üß© –í–Ω—É—Ç—Ä—ñ—à–Ω—ñ –º–æ–¥—É–ª—ñ –ø—Ä–æ—î–∫—Ç—É

__all__ = ["normalize_size_token", "normalize_stock_map"]

# ================================
# ‚öôÔ∏è –ö–û–ù–°–¢–ê–ù–¢–ò –ú–û–î–£–õ–Ø
# ================================
_MAX_X_REPEATS = 4                                          # üßÆ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å X —É –ª—ñ—Ç–µ—Ä–∞–ª—å–Ω–∏—Ö —Ä–æ–∑–º—ñ—Ä–∞—Ö
_CYRILLIC_TO_LATIN = {"—Ö": "x"}                             # üî§ –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–∏—Ä–∏–ª–∏—á–Ω–∏—Ö –ª—ñ—Ç–µ—Ä —É –ª–∞—Ç–∏–Ω–∏—Ü—é


# ================================
# üßπ –ü–†–ò–í–ê–¢–ù–Ü –î–û–ü–û–ú–Ü–ñ–ù–Ü –§–£–ù–ö–¶–Ü–á
# ================================
def _basic_clean(token: str) -> str:
    """
    üßπ –û—á–∏—â—É—î —Å–∏—Ä–∏–π —Ç–æ–∫–µ–Ω: —Ç—Ä—ñ–º, –Ω–∏–∂–Ω—ñ–π —Ä–µ–≥—ñ—Å—Ç—Ä, –∑–∞–º—ñ–Ω–∞ –∫–∏—Ä–∏–ª–∏—Ü—ñ —Ç–∞ —Ñ—ñ–ª—å—Ç—Ä —Å–∏–º–≤–æ–ª—ñ–≤.

    Args:
        token (str): –í—Ö—ñ–¥–Ω–∏–π —Ä—è–¥–æ–∫ –∑ —Ä–æ–∑–º—ñ—Ä–æ–º.

    Returns:
        str: –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π —Ä—è–¥–æ–∫, —â–æ –º—ñ—Å—Ç–∏—Ç—å –ª–∏—à–µ [0-9a-z].
    """
    cleaned = (token or "").strip().lower()                 # ‚úÇÔ∏è –û–±—Ä—ñ–∑–∞—î–º–æ –ø—Ä–æ–±—ñ–ª–∏ —Ç–∞ –≥–æ—Ç—É—î–º–æ —Ä–µ–≥—ñ—Å—Ç—Ä
    if not cleaned:
        return ""

    for cyrillic, latin in _CYRILLIC_TO_LATIN.items():
        cleaned = cleaned.replace(cyrillic, latin)          # üîÑ –ó–∞–º—ñ–Ω—é—î–º–æ –∫–∏—Ä–∏–ª–∏—á–Ω—ñ —Å–∏–º–≤–æ–ª–∏ –Ω–∞ –ª–∞—Ç–∏–Ω—Å—å–∫—ñ

    return re.sub(r"[^0-9a-z]", "", cleaned)                # üßº –í—ñ–¥–∫–∏–¥–∞—î–º–æ –≤—Å–µ, —â–æ –Ω–µ —Ü–∏—Ñ—Ä–∏ —Ç–∞ –ª–∞—Ç–∏–Ω—Å—å–∫—ñ –ª—ñ—Ç–µ—Ä–∏


def _x_block_to_size(x_block: str) -> Optional[str]:
    """
    ‚ùå –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å 'x...' —É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—É —á–∞—Å—Ç–∏–Ω—É –ø–æ–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä—É.

    Args:
        x_block (str): –§—Ä–∞–≥–º–µ–Ω—Ç, —â–æ —Å–∫–ª–∞–¥–∞—î—Ç—å—Å—è –ª–∏—à–µ –∑ —Å–∏–º–≤–æ–ª—ñ–≤ 'x'.

    Returns:
        Optional[str]: –†—è–¥–æ–∫ –∑ –≤–µ–ª–∏–∫–æ—é –ª—ñ—Ç–µ—Ä–æ—é `X` –∞–±–æ None, —è–∫—â–æ —à–∞–±–ª–æ–Ω –Ω–µ–¥—ñ–π—Å–Ω–∏–π.
    """
    if not x_block:
        return None
    if len(x_block) > _MAX_X_REPEATS:
        return None
    return "X" * len(x_block)                               # ‚ùé –§–æ—Ä–º—É—î–º–æ —á–∞—Å—Ç–∏–Ω—É —Ç–∏–ø—É 'XX' —Ç–æ—â–æ


def _canonical_from_core_rules(cleaned: str) -> Optional[str]:
    """
    üìê –ó–∞—Å—Ç–æ—Å–æ–≤—É—î –±–∞–∑–æ–≤—ñ –ø—Ä–∞–≤–∏–ª–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó –±–µ–∑ aliases.

    Args:
        cleaned (str): –í–∂–µ –æ—á–∏—â–µ–Ω–∏–π —Ç–æ–∫–µ–Ω.

    Returns:
        Optional[str]: –ö–∞–Ω–æ–Ω—ñ—á–Ω–∏–π —Ä–æ–∑–º—ñ—Ä (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 'XS', '28') –∞–±–æ None, —è–∫—â–æ –Ω–µ —Å–ø—ñ–≤–ø–∞–ª–æ.
    """
    if not cleaned:
        return None

    if cleaned.isdigit():
        return cleaned

    match_multi = re.fullmatch(r"([234])xl", cleaned)       # üîÅ –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ –∑–∞–ø–∏—Å—ñ–≤ –Ω–∞ –∫—à—Ç–∞–ª—Ç 2XL/3XL/4XL
    if match_multi:
        multiplier = int(match_multi.group(1))              # üßÆ –û—Ç—Ä–∏–º—É—î–º–æ –º–Ω–æ–∂–Ω–∏–∫ –¥–ª—è 'X'
        return "X" * multiplier + "L"                       # üìè –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –Ω–∞ –∫–∞–Ω–æ–Ω—ñ—á–Ω–∏–π –∑–∞–ø–∏—Å

    match_tail = re.fullmatch(r"(x{1,4})(s|l)", cleaned)    # üßµ –ü–∞—Ç–µ—Ä–Ω –¥–ª—è XS/XL/XXL‚Ä¶
    if match_tail:
        x_part = _x_block_to_size(match_tail.group(1))      # üßÆ –§–æ—Ä–º—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å X
        tail = match_tail.group(2).upper()                  # üî† –ü—Ä–∏–≤–æ–¥–∏–º–æ —Å—É—Ñ—ñ–∫—Å –¥–æ –≤–µ—Ä—Ö–Ω—å–æ–≥–æ —Ä–µ–≥—ñ—Å—Ç—Ä—É
        if x_part:
            return f"{x_part}{tail}"                        # üß∑ –°–∫–ª–µ—é—î–º–æ –∫–∞–Ω–æ–Ω—ñ—á–Ω–∏–π —Ä–æ–∑–º—ñ—Ä

    # Shopify —ñ–Ω–∫–æ–ª–∏ –ø–æ–≤–µ—Ä—Ç–∞—î —Å—É—Ñ—ñ–∫—Å–∞–º–∏ Small/Large (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "XXSmall" –∞–±–æ "XXLarge")
    match_word_tail = re.fullmatch(r"(x{1,4})(small|large)", cleaned)
    if match_word_tail:
        x_part = _x_block_to_size(match_word_tail.group(1))
        if x_part:
            suffix = match_word_tail.group(2)
            tail = "S" if suffix.startswith("s") else "L"
            return f"{x_part}{tail}"

    if cleaned in {"s", "m", "l"}:
        return cleaned.upper()

    return None


def _prepare_alias_map(raw_aliases: Optional[Mapping[str, str]]) -> Dict[str, str]:
    """
    üóÉÔ∏è –ü—ñ–¥–≥–æ—Ç–æ–≤–ª—é—î –º–∞–ø—É aliases –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –ø–æ—à—É–∫—É.

    Args:
        raw_aliases (Mapping[str, str] | None): –°–∏—Ä—ñ –¥–∞–Ω—ñ –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.

    Returns:
        Dict[str, str]: –ú–∞–ø–∞ –æ—á–∏—â–µ–Ω–∏—Ö –∫–ª—é—á—ñ–≤ –¥–æ –∫–∞–Ω–æ–Ω—ñ—á–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å.
    """
    if not raw_aliases:
        return {}

    prepared: Dict[str, str] = {}
    for raw_key, raw_value in raw_aliases.items():
        cleaned_key = _basic_clean(str(raw_key))            # ü™ü –£–Ω—ñ—Ñ—ñ–∫—É—î–º–æ –∫–ª—é—á alias
        if not cleaned_key:
            continue

        value = (raw_value or "").strip()                   # üßµ –ü—Ä–∞—Ü—é—î–º–æ –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–º –∑–Ω–∞—á–µ–Ω–Ω—è–º
        if not value:
            continue

        canonical = _canonical_from_core_rules(_basic_clean(value)) or value.upper()  # üß≠ –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫—ñ–Ω—Ü–µ–≤–∏–π —Ä–æ–∑–º—ñ—Ä
        prepared[cleaned_key] = canonical                    # üìå –ó–∞–ø–∞–º'—è—Ç–æ–≤—É—î–º–æ —É –º–∞–ø—ñ

    return prepared


# ================================
# üéØ –ü–£–ë–õ–Ü–ß–ù–Ü –§–£–ù–ö–¶–Ü–á
# ================================
def normalize_size_token(raw: str, *, aliases: Optional[Mapping[str, str]] = None) -> str:
    """
    üéØ –ù–æ—Ä–º–∞–ª—ñ–∑—É—î –æ–∫—Ä–µ–º–∏–π —Ç–æ–∫–µ–Ω —Ä–æ–∑–º—ñ—Ä—É –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º aliases.

    Args:
        raw (str): –í—Ö—ñ–¥–Ω–∏–π —Ä–æ–∑–º—ñ—Ä —É –¥–æ–≤—ñ–ª—å–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ.
        aliases (Mapping[str, str] | None): –ú–∞–ø–∞ —Å–∏–Ω–æ–Ω—ñ–º—ñ–≤ –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.

    Returns:
        str: –ö–∞–Ω–æ–Ω—ñ—á–Ω–∏–π —Ä–æ–∑–º—ñ—Ä –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫, —è–∫—â–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –Ω–µ –≤–¥–∞–ª–æ—Å—è.
    """
    if not raw:
        return ""

    cleaned = _basic_clean(raw)                             # üßπ –ü—Ä–æ–≤–æ–¥–∏–º–æ –±–∞–∑–æ–≤–µ –æ—á–∏—â–µ–Ω–Ω—è —Ç–æ–∫–µ–Ω–∞
    if not cleaned:
        return ""

    core = _canonical_from_core_rules(cleaned)              # üß≠ –ü—Ä–æ–±—É—î–º–æ –ø–æ–±—É–¥—É–≤–∞—Ç–∏ –∫–∞–Ω–æ–Ω—ñ—á–Ω–∏–π —Ä–æ–∑–º—ñ—Ä –∑ –ø—Ä–∞–≤–∏–ª —è–¥—Ä–∞
    if core:
        return core

    alias_map = _prepare_alias_map(aliases)                 # üóÉÔ∏è –ü—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–µ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è aliases
    if cleaned in alias_map:
        return alias_map[cleaned]                           # ü™Ñ –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Ä–æ–∑–º—ñ—Ä –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó

    return ""


def normalize_stock_map(
    stock: Mapping[str, Mapping[str, bool]] | Dict[str, Dict[str, bool]] | None,
    *,
    locale: Optional[str] = None,
    aliases: Optional[Mapping[str, str]] = None,
) -> Dict[str, Dict[str, bool]]:
    """
    üóÑÔ∏è –ù–æ—Ä–º–∞–ª—ñ–∑—É—î –∫–∞—Ä—Ç—É –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ —Ç–æ–≤–∞—Ä—ñ–≤ –∑–∞ —Ä–æ–∑–º—ñ—Ä–∞–º–∏.

    Args:
        stock (Mapping[str, Mapping[str, bool]] | Dict[str, Dict[str, bool]] | None):
            –ü–æ—á–∞—Ç–∫–æ–≤–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑—ñ stock-data.
        locale (str | None): –ó–∞—Ä–µ–∑–µ—Ä–≤–æ–≤–∞–Ω–∏–π –∞—Ä–≥—É–º–µ–Ω—Ç (–¥–ª—è —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ, –∑–∞—Ä–∞–∑ –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è).
        aliases (Mapping[str, str] | None): –ú–∞–ø–∞ —Å–∏–Ω–æ–Ω—ñ–º—ñ–≤ —Ä–æ–∑–º—ñ—Ä—ñ–≤.

    Returns:
        Dict[str, Dict[str, bool]]: –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑ –∫–∞–Ω–æ–Ω—ñ—á–Ω–∏–º–∏ —Ä–æ–∑–º—ñ—Ä–∞–º–∏.
    """
    if not stock:
        return {}

    normalized: Dict[str, Dict[str, bool]] = {}             # üì¶ –§—ñ–Ω–∞–ª—å–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫ –∑ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏

    for color, sizes in stock.items():
        if not color or not sizes:
            continue

        normalized_sizes: Dict[str, bool] = {}              # üéØ –ú–∞–ø–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö —Ä–æ–∑–º—ñ—Ä—ñ–≤ –¥–ª—è –∫–æ–ª—å–æ—Ä—É

        for size_token, available in sizes.items():
            normalized_token = normalize_size_token(size_token, aliases=aliases)  # üìè –£–Ω—ñ—Ñ—ñ–∫—É—î–º–æ —Ç–æ–∫–µ–Ω
            if not normalized_token:
                continue
            normalized_sizes[normalized_token] = bool(available)  # ‚úÖ –§—ñ–∫—Å—É—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å

        if normalized_sizes:
            normalized[str(color)] = normalized_sizes       # üì¶ –î–æ–¥–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –Ω–µ–Ω—É–ª—å–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

    return normalized
