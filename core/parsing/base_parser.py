""" üß† base_parser.py ‚Äî –ë–∞–∑–æ–≤–∏–π –∫–ª–∞—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É —Å—Ç–æ—Ä—ñ–Ω–æ–∫ —Ç–æ–≤–∞—Ä—ñ–≤ YoungLA.

üîπ –ö–ª–∞—Å `BaseParser`:
- –°–∞–º–æ—Å—Ç—ñ–π–Ω–æ –≤–∏–∑–Ω–∞—á–∞—î –≤–∞–ª—é—Ç—É –ø–æ URL
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î HTML —á–µ—Ä–µ–∑ Playwright
- –í–∏—Ç—è–≥—É—î —Ü—ñ–Ω—É, –æ–ø–∏—Å, –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è, –∫–æ–ª—å–æ—Ä–∏, —Ä–æ–∑–º—ñ—Ä–∏, –Ω–∞—è–≤–Ω—ñ—Å—Ç—å
- –§–æ—Ä–º—É—î —Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫ –¥–ª—è Telegram
"""

# üì¶ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ñ
import re
import time
import json
import logging
import asyncio
from typing import Dict, Any, Optional

# üåê –ü–∞—Ä—Å–∏–Ω–≥ HTML
from bs4 import BeautifulSoup

# üß± –°–µ—Ä–≤—ñ—Å–∏
from core.webdriver.webdriver_service import WebDriverService
from core.config.config_service import ConfigService
from bot.content.translator import TranslatorService
from core.parsing.color_size_formatter import ColorSizeFormatter

# üß∞ –£—Ç–∏–ª—ñ—Ç–∏
from utils.region_utils import get_currency_from_url

# üì¶ –ú–æ–¥–µ–ª—ñ –¥–∞–Ω–∏—Ö
from models.product_info import ProductInfo

# üñ• –í–∏–≤—ñ–¥ —É –∫–æ–Ω—Å–æ–ª—å
from rich.progress import Progress, SpinnerColumn, BarColumn, TimeElapsedColumn, TextColumn

class BaseParser:
    def __init__(self, url: str, enable_progress: bool = True):
        self.url = url
        self._currency = get_currency_from_url(url)
        self.enable_progress = enable_progress
        self.page_source: Optional[str] = None
        self.soup: Optional[BeautifulSoup] = None
        self.config = ConfigService()
        self.translator = TranslatorService()

    async def fetch_page(self, retries: int = 5) -> bool:
        self.page_source = None
        start_time = time.time()
    
        for attempt in range(1, retries + 1):
            if self.enable_progress:
                from rich.progress import Progress, SpinnerColumn, BarColumn, TimeElapsedColumn, TextColumn
    
                with Progress(
                    SpinnerColumn(),
                    BarColumn(bar_width=24),
                    TextColumn("[progress.description]{task.description}"),
                    TimeElapsedColumn(),
                    transient=True,
                ) as progress:
                    task = progress.add_task(f"üåç –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (—Å–ø—Ä–æ–±–∞ {attempt})...", total=100)
    
                    for step in range(100):
                        if step % 5 == 0:
                            self.page_source = await WebDriverService().fetch_page_source(self.url)
                            if self.page_source:
                                self.soup = BeautifulSoup(self.page_source, "html.parser")
                                logging.info(f"‚úÖ –°—Ç–æ—Ä—ñ–Ω–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {self.url}")
                                logging.info(f"‚è≥ –ß–∞—Å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {time.time() - start_time:.2f} —Å–µ–∫.")
                                return True
                        await asyncio.sleep(0.05)
                        progress.update(task, advance=1)
            else:
                # üîá –¢–∏—Ö–∏–π —Ä–µ–∂–∏–º –±–µ–∑ –ø—Ä–æ–≥—Ä–µ—Å—É
                self.page_source = await WebDriverService().fetch_page_source(self.url)
                if self.page_source:
                    self.soup = BeautifulSoup(self.page_source, "html.parser")
                    return True
                await asyncio.sleep(2)
    
            logging.warning(f"üîÑ –°–ø—Ä–æ–±–∞ {attempt}: –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É...")
    
        logging.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É: {self.url}")
        return False

    # --- –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö ---

    async def extract_title(self) -> str:
        title_tag = self.soup.find("h1")
        return title_tag.text.strip() if title_tag else "–ë–µ–∑ –Ω–∞–∑–≤–∏"

    async def extract_price(self) -> float:
        meta = self.soup.find("meta", {"property": "product:price:amount"})
        if meta:
            try:
                return float(meta["content"].replace(",", "."))
            except ValueError:
                logging.warning(f"‚ö†Ô∏è –ù–µ–º–æ–∂–ª–∏–≤–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ —Ü—ñ–Ω—É: {meta['content']}")
        return 0.0

    async def extract_detailed_sections(self) -> dict:
        sections = {}
        accordion = self.soup.select_one("#ProductAccordion")
        if accordion:
            for detail in accordion.select("details"):
                summary = detail.find("summary")
                body = detail.find("div")
                if summary and body:
                    key = summary.get_text(strip=True).upper()
                    value = body.get_text(separator="\n", strip=True)
                    sections[key] = value
        return sections

    async def extract_description(self) -> str:
        meta = self.soup.find("meta", {"name": "twitter:description"})
        return meta["content"] if meta else "–û–ø–∏—Å –≤—ñ–¥—Å—É—Ç–Ω—ñ–π"

    async def extract_image(self) -> str:
        meta = self.soup.find("meta", {"property": "og:image"})
        return meta["content"] if meta else "–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤—ñ–¥—Å—É—Ç–Ω—î"

    async def extract_all_images(self) -> list[str]:
        images = []
        gallery = self.soup.select_one(".product-gallery__thumbnail-list")
        if gallery:
            for img in gallery.select("button img[src]"):
                url = img["src"]
                if url.startswith("//"):
                    url = "https:" + url
                images.append(url)
                logging.info(f"üì∏ –ó–Ω–∞–π–¥–µ–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {url}")
        return images

    async def extract_colors_from_html(self) -> list[str]:
        colors = []
        swatch_block = self.soup.find("div", class_="product-form__swatch color")
        if swatch_block:
            inputs = swatch_block.find_all("input", {"name": "Color"})
            for input_tag in inputs:
                color_name = input_tag.get("value", "").strip()
                if color_name:
                    colors.append(color_name)
        return colors

    async def extract_colors_sizes(self) -> dict:
        color_size_map = {}

        color_blocks = self.soup.select('.variant-picker__option label.color-swatch span')
        if color_blocks:
            for block in color_blocks:
                color = block.get_text(strip=True)
                if color:
                    color_size_map[color] = []

            size_blocks = self.soup.select('.variant-picker__option label.block-swatch span')
            raw_sizes = [size.get_text(strip=True) for size in size_blocks if size.get_text(strip=True)]
            clean_sizes = [self._map_size(size) for size in raw_sizes]

            for color in color_size_map:
                color_size_map[color] = clean_sizes

        if not color_size_map:
            colors = await self.extract_colors_from_html()
            if colors:
                color_size_map = {color: [] for color in colors}

        logging.info(f"üì¶ –ö–∞—Ä—Ç–∞ –∫–æ–ª—å–æ—Ä—ñ–≤/—Ä–æ–∑–º—ñ—Ä—ñ–≤ (–∑ HTML fallback): {color_size_map}")
        return color_size_map

    async def extract_color_size_availability(self) -> dict:
        stock = {}
        for script in self.soup.find_all("script", {"type": "application/ld+json"}):
            try:
                data = json.loads(script.string)
                if isinstance(data, dict) and data.get("@type") == "Product" and "offers" in data:
                    for offer in data["offers"]:
                        name = offer.get("name", "")
                        available = "InStock" in offer.get("availability", "")
                        if " / " in name:
                            color, size = name.split(" / ")
                            stock.setdefault(color.strip(), {})[self._map_size(size.strip())] = available
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è JSON-LD parsing error: {e}")
        return stock

    async def determine_weight(self, title: str, description: str, image_url: str) -> float:
        weight_data = self.config.load_weight_data()
        weight = next((w for k, w in weight_data.items() if k in title.lower()), None)

        if weight is None:
            logging.info(f"ü§ñ –í–∏–∑–Ω–∞—á–∞—î–º–æ –≤–∞–≥—É —á–µ—Ä–µ–∑ GPT –¥–ª—è: {title}")
            weight = self.translator.get_weight_estimate(title, description, image_url)
            self.config.update_weight_dict(title.lower(), weight)

        logging.info(f"‚úÖ –í–∏–∑–Ω–∞—á–µ–Ω–∞ –≤–∞–≥–∞: {weight} –∫–≥")
        return weight

    async def is_product_available(self) -> bool:
        for script in self.soup.find_all("script", {"type": "application/ld+json"}):
            try:
                data = json.loads(script.string)
                if isinstance(data, dict) and data.get("@type") == "Product" and "offers" in data:
                    for offer in data["offers"]:
                        if "InStock" in offer.get("availability", ""):
                            return True
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è JSON-LD parsing error: {e}")
        return False

    def _map_size(self, raw_size: str) -> str:
        size_mapping = {
            "XXSmall": "XXS", "XSmall": "XS", "Small": "S", "Medium": "M",
            "Large": "L", "XLarge": "XL", "XXLarge": "XXL", "XXXLarge": "XXXL"
        }
        clean = re.sub(r'[^a-zA-Z]', '', raw_size)
        return size_mapping.get(clean, clean)

    # --- –§–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö ---

    async def format_colors_with_stock(self) -> str:
        color_size_map = await self.extract_colors_sizes()
        stock_data = await self.extract_color_size_availability()

        if not stock_data:
            stock_data = {
                color: {size: True for size in sizes}
                for color, sizes in color_size_map.items()
            }

        return ColorSizeFormatter.format_color_size_availability(stock_data)

    async def parse(self) -> Dict[str, Any]:
        # ‚è¨ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ HTML —Å—Ç–æ—Ä—ñ–Ω–∫—É
        if not await self.fetch_page():
            return {}

        title = await self.extract_title()  # üè∑ –ù–∞–∑–≤–∞ —Ç–æ–≤–∞—Ä—É
        description = await self.extract_description()  # üìù –ö–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å –∑ –º–µ—Ç–∞-—Ç–µ–≥–∞ (Twitter)

        # üìë –í–∏—Ç—è–≥—É—î–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–µ–∫—Ü—ñ—ó (Care Instructions, Fit Guide —Ç–æ—â–æ)
        detailed_sections = await self.extract_detailed_sections()

        # üß† –Ø–∫—â–æ –æ–ø–∏—Å—É –Ω–µ–º–∞—î –∞–±–æ –≤—ñ–Ω –Ω–∞–¥—Ç–æ –∫–æ—Ä–æ—Ç–∫–∏–π ‚Äî –±–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π –±–ª–æ–∫ —ñ–∑ detailed_sections
        if not description or len(description.strip()) < 20:
            if detailed_sections:
                first_key = next(iter(detailed_sections))
                description = detailed_sections[first_key]

        image_url = await self.extract_image()  # üñº –û—Å–Ω–æ–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–æ–≤–∞—Ä—É
        colors_text = await self.format_colors_with_stock()  # üé® –ö–æ–ª—å–æ—Ä–∏ + –Ω–∞—è–≤–Ω—ñ—Å—Ç—å
        weight = await self.determine_weight(title, description, image_url)  # ‚öñÔ∏è –í–∞–≥–∞ (–∑ title/–æ–ø–∏—Å—É/GPT)
        images = await self.extract_all_images()  # üñº –ì–∞–ª–µ—Ä–µ—è
        price = await self.extract_price() # üíµ –¶—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É
        currency = self.currency # üí≤ –í–∞–ª—é—Ç–∞ (–≤–∏–∑–Ω–∞—á–∞—î—Ç—å—Å—è –ø–æ URL)

        # üßæ –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Å–ª–æ–≤–Ω–∏–∫ –¥–∞–Ω–∏—Ö —Ç–æ–≤–∞—Ä—É
        return {
            "title": title, # üè∑ –ù–∞–∑–≤–∞ —Ç–æ–≤–∞—Ä—É
            "price": price, # üíµ –¶—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É
            "currency": currency, # üí≤ –í–∞–ª—é—Ç–∞ (–≤–∏–∑–Ω–∞—á–∞—î—Ç—å—Å—è –ø–æ URL)
            "description": description, # üìù –ö–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å –∑ –º–µ—Ç–∞-—Ç–µ–≥–∞ (Twitter)
            "main_image": image_url, # üñº –û—Å–Ω–æ–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–æ–≤–∞—Ä—É (–¥–ª—è Telegram-–ø—Ä–µ–≤ º—é)
            "colors_sizes": colors_text, # üé® –§–æ—Ä–º–∞—Ç–æ–≤–∞–Ω—ñ –∫–æ–ª—å–æ—Ä–∏ —Ç–∞ —Ä–æ–∑–º—ñ—Ä–∏ (–∑ –Ω–∞—è–≤–Ω—ñ—Å—Ç—é)
            "images": images, # üñº –£—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–æ–≤–∞—Ä—É (–¥–ª—è –≥–∞–ª–µ—Ä–µ—ó)
            "weight": weight, # ‚öñÔ∏è –í–∞–≥–∞ —Ç–æ–≤–∞—Ä—É (–ø–æ –Ω–∞–∑–≤—ñ / GPT)
            "sections": detailed_sections
        }

    async def get_product_info(self) -> ProductInfo:
        try:
            data = await self.parse()
            self.page_source = getattr(self, "page_source", None)

            return ProductInfo(
                title=str(data.get("title", "–ù–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è")),
                price=float(data.get("price", 0.0)),
                description=str(data.get("description", "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è")),
                image_url=str(data.get("main_image", "")),
                weight=float(data.get("weight", 0.5)),
                colors_text=str(data.get("colors_sizes", "")),
                images=data.get("images", []),
                currency=str(data.get("currency", "USD")),
                sections=data.get("sections", {})  # ‚¨ÖÔ∏è —Å—é–¥–∞
            )

        except Exception as e:
            logging.exception(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥—É —Ç–æ–≤–∞—Ä—É: {e}")
            return ProductInfo(
                title="–ü–æ–º–∏–ª–∫–∞",
                price=0.0,
                description="–ü–æ–º–∏–ª–∫–∞",
                image_url="",
                weight=0.5,
                colors_text="",
                images=[],
                currency="USD",
                sections=data.get("sections", {})
            )

    @property
    def currency(self) -> str:
        return self._currency
